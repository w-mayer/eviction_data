{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement fuzzy matching on LLCs that have filed evictions to lookup registered LLC info\n",
    "\n",
    "Updated 4/4/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import unicodedata\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.read_parquet('DATA/evictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llc_df = pd.read_parquet('DATA/llc.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservative pre-processing approach to maintain efficiency\n",
    "\n",
    "Can make this more aggressive if it doesn't work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_names(df, column_name):\n",
    "    \"\"\"\n",
    "    Normalize names, sort words alphabetically for natural language processing if we need it later\n",
    "    @df: pandas dataframe\n",
    "    @column_name: str column name to preprocess\n",
    "    \n",
    "    \"\"\"\n",
    "    column = column_name + \"_normalized\"\n",
    "    df[column] = (\n",
    "        df[column_name]\n",
    "        .str.lower()\n",
    "        .str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "    ) \n",
    "\n",
    "    df[column] = (\n",
    "        df[column]\n",
    "        .str.split()\n",
    "        .map(lambda x: \" \".join(sorted(x)) if isinstance(x, list) else ' ')\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_columns_for_p = ['plaintiff_name'] # columns for preprocessing, add more as needed\n",
    "l_columns_for_p = ['EntityID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in e_columns_for_p: # apply preprocessing for both df\n",
    "    evictions_df = preprocess_names(evictions_df, i)\n",
    "\n",
    "for i in l_columns_for_p:\n",
    "    llc_df = preprocess_names(llc_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_759534/2018107948.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  evictions[\"is_llc\"] = evictions[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)\n"
     ]
    }
   ],
   "source": [
    "# create flag 'is_llc' to restrict lookup to only llcs\n",
    "llc_keywords = r\"\\b(llc|l\\.l\\.c|inc|inc\\.|corporation|corp|corp\\.|co|co\\.|company|ltd|ltd\\.|lp|l\\.p\\.|pllc|plc|plc\\.|limited|limited liability company)\\b\"\n",
    "evictions_df[\"is_llc\"] = evictions_df[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = evictions_df[evictions_df['is_llc']] # restrict lookup to only llcs\n",
    "plaintiffs = set(evictions_df['plaintiff_name_normalized']) # set of unique LLC plaintiffs\n",
    "llcs = set(llc_df['EntityID_normalized']) # set of unique registered LLCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process matching for a subset of plaintiff names\n",
    "def process_chunk(plaintiff_chunk, llc_names, confidence=80):\n",
    "    matches = {}\n",
    "    for i, plaintiff in enumerate(plaintiff_chunk):\n",
    "        best_match, score = process.extractOne(plaintiff, llc_names, scorer=fuzz.WRatio)\n",
    "        if best_match >= confidence:\n",
    "            matches[plaintiff] = best_match[0]\n",
    "        else:\n",
    "            matches[plaintiff] = None\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} out of {len(plaintiff_chunk)} plaintiffs in this chunk.\")\n",
    "    return matches\n",
    "\n",
    "# Function to split the plaintiff set and process in parallel\n",
    "def parallel_match_plaintiffs(plaintiff_names_set, llc_names_set, chunk_size=1000):\n",
    "    plaintiff_chunks = [list(plaintiff_names_set)[i:i + chunk_size] for i in range(0, len(plaintiff_names_set), chunk_size)]\n",
    "    print(f\"Total of {len(plaintiff_chunks)} chunks to process.\")\n",
    "\n",
    "    all_matches = {}\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_chunk, chunk, llc_names_set) for chunk in plaintiff_chunks]\n",
    "        for i, future in enumerate(futures):\n",
    "            all_matches.update(future.result())\n",
    "            print(f\"Chunk {i + 1} processed. Total matches found: {len(all_matches)}\")\n",
    "    \n",
    "    return all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = len(plaintiffs) // 16 # adjust for num of cores, 16 worked well under an hour\n",
    "# probably only needed ~100GB memory or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 17 chunks to process.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.Processed 500 out of 973 plaintiffs in this chunk.\n",
      "\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.Processed 700 out of 973 plaintiffs in this chunk.\n",
      "\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Chunk 1 processed. Total matches found: 973\n",
      "Chunk 2 processed. Total matches found: 1946\n",
      "Chunk 3 processed. Total matches found: 2919\n",
      "Chunk 4 processed. Total matches found: 3892\n",
      "Chunk 5 processed. Total matches found: 4865\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Chunk 6 processed. Total matches found: 5838\n",
      "Chunk 7 processed. Total matches found: 6811\n",
      "Chunk 8 processed. Total matches found: 7784\n",
      "Chunk 9 processed. Total matches found: 8757\n",
      "Chunk 10 processed. Total matches found: 9730\n",
      "Chunk 11 processed. Total matches found: 10703\n",
      "Chunk 12 processed. Total matches found: 11676\n",
      "Chunk 13 processed. Total matches found: 12649\n",
      "Chunk 14 processed. Total matches found: 13622\n",
      "Chunk 15 processed. Total matches found: 14595\n",
      "Chunk 16 processed. Total matches found: 15568\n",
      "Chunk 17 processed. Total matches found: 15573\n"
     ]
    }
   ],
   "source": [
    "matches = parallel_match_plaintiffs(plaintiffs, llcs, chunk_size=chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and cb inc rentals sales -> and building llc remodeling springbuck\n",
      "ann commons lp wingfield -> ann commons llc wingfield\n",
      "lp stuart woods -> crystal llc owner woods\n",
      "adirondack llc -> adirondack llc\n",
      "llc mhci wap -> llc m\n",
      "apts creeks edge llc -> edge llc\n",
      "cedar gri llc park -> cedar gri llc park\n",
      "estates llc mobile riverview -> estates llc mobile riverview\n",
      "llc two wh -> llc two wh\n",
      "college lp mission nrha -> college llc mission nrha\n"
     ]
    }
   ],
   "source": [
    "for plaintiff, llc in list(matches.items())[:10]:\n",
    "    print(f\"{plaintiff} -> {llc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df['best_match'] = evictions_df['plaintiff_name_normalized'].map(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.merge(\n",
    "    left=evictions_df,\n",
    "    right=llc_df,\n",
    "    left_on='best_match',\n",
    "    right_on='EntityID_normalized',\n",
    "    how='left'\n",
    ").drop(columns=['best_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions.to_parquet('evictions_matched.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
