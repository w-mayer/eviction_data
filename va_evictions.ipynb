{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement fuzzy matching on LLCs that have filed evictions to lookup registered LLC info\n",
    "\n",
    "Updated 4/4/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import unicodedata\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.read_parquet('DATA/evictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llc_df = pd.read_parquet('DATA/llc.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservative pre-processing approach to maintain efficiency\n",
    "\n",
    "Can make this more aggressive if it doesn't work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_names(df, column_name):\n",
    "    \"\"\"\n",
    "    Normalize names, sort words alphabetically for natural language processing if we need it later\n",
    "    @df: pandas dataframe\n",
    "    @column_name: str column name to preprocess\n",
    "    \n",
    "    \"\"\"\n",
    "    column = column_name + \"_normalized\"\n",
    "    df[column] = (\n",
    "        df[column_name]\n",
    "        .str.lower()\n",
    "        .str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.strip()\n",
    "    ) \n",
    "\n",
    "    df[column] = (\n",
    "        df[column]\n",
    "        .str.split()\n",
    "        .map(lambda x: \" \".join(sorted(x)) if isinstance(x, list) else ' ')\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_columns_for_p = ['plaintiff_name'] # columns for preprocessing, add more as needed\n",
    "l_columns_for_p = ['EntityID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in e_columns_for_p: # apply preprocessing for both df\n",
    "    evictions_df = preprocess_names(evictions_df, i)\n",
    "\n",
    "for i in l_columns_for_p:\n",
    "    llc_df = preprocess_names(llc_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_759534/2018107948.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  evictions[\"is_llc\"] = evictions[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)\n"
     ]
    }
   ],
   "source": [
    "# create flag 'is_llc' to restrict lookup to only llcs\n",
    "llc_keywords = r\"\\b(llc|l\\.l\\.c|inc|inc\\.|corporation|corp|corp\\.|co|co\\.|company|ltd|ltd\\.|lp|l\\.p\\.|pllc|plc|plc\\.|limited|limited liability company)\\b\"\n",
    "evictions_df[\"is_llc\"] = evictions_df[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've set the 'is_llc' flag, we can remove these terms to reduce noise\n",
    "suffixes = [\n",
    "    \"llc\", \"l.l.c\", \"inc\", \"incorporated\", \"corp\", \"corporation\",\n",
    "    \"co\", \"company\", \"ltd\", \"l.p\", \"lp\", \"pllc\", \"plc\", \"llp\", \"p.c\"\n",
    "]\n",
    "\n",
    "suffix_pattern = r'\\s*(?:' + '|'.join(suffixes) + r')\\.?\\s*$'\n",
    "\n",
    "evictions_df['plaintiff_name_normalized'] = evictions_df['plaintiff_name_normalized'].str.replace(suffix_pattern, '', regex=True)\n",
    "llc_df['EntityID_normalized'] = llc_df['EntityID_normalized'].str.replace(suffix_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = evictions_df[evictions_df['is_llc']] # restrict lookup to only llcs\n",
    "plaintiffs = set(evictions_df['plaintiff_name_normalized']) # set of unique LLC plaintiffs\n",
    "llcs = set(llc_df['EntityID_normalized']) # set of unique registered LLCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process matching for a subset of plaintiff names\n",
    "def process_chunk(plaintiff_chunk, llc_names, confidence=80):\n",
    "    matches = {}\n",
    "    for i, plaintiff in enumerate(plaintiff_chunk):\n",
    "        best_match, score = process.extractOne(plaintiff, llc_names, scorer=fuzz.WRatio)\n",
    "        if best_match and score >= confidence:\n",
    "            matches[plaintiff] = (best_match, score)\n",
    "        else:\n",
    "            matches[plaintiff] = (None, 0)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} out of {len(plaintiff_chunk)} plaintiffs in this chunk.\")\n",
    "    return matches\n",
    "\n",
    "# Function to split the plaintiff set and process in parallel\n",
    "def parallel_match_plaintiffs(plaintiff_names_set, llc_names_set, chunk_size=1000):\n",
    "    plaintiff_chunks = [list(plaintiff_names_set)[i:i + chunk_size] for i in range(0, len(plaintiff_names_set), chunk_size)]\n",
    "    print(f\"Total of {len(plaintiff_chunks)} chunks to process.\")\n",
    "\n",
    "    all_matches = {}\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_chunk, chunk, llc_names_set) for chunk in plaintiff_chunks]\n",
    "        for i, future in enumerate(futures):\n",
    "            all_matches.update(future.result())\n",
    "            print(f\"Chunk {i + 1} processed. Total matches found: {len(all_matches)}\")\n",
    "    \n",
    "    return all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = len(plaintiffs) // 16 # adjust for num of cores, 16 worked well under an hour\n",
    "# probably only needed ~100GB memory or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 17 chunks to process.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 100 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 200 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 300 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 400 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.Processed 500 out of 973 plaintiffs in this chunk.\n",
      "\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 500 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 600 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.Processed 700 out of 973 plaintiffs in this chunk.\n",
      "\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 700 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 800 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Chunk 1 processed. Total matches found: 973\n",
      "Chunk 2 processed. Total matches found: 1946\n",
      "Chunk 3 processed. Total matches found: 2919\n",
      "Chunk 4 processed. Total matches found: 3892\n",
      "Chunk 5 processed. Total matches found: 4865\n",
      "Processed 900 out of 973 plaintiffs in this chunk.\n",
      "Chunk 6 processed. Total matches found: 5838\n",
      "Chunk 7 processed. Total matches found: 6811\n",
      "Chunk 8 processed. Total matches found: 7784\n",
      "Chunk 9 processed. Total matches found: 8757\n",
      "Chunk 10 processed. Total matches found: 9730\n",
      "Chunk 11 processed. Total matches found: 10703\n",
      "Chunk 12 processed. Total matches found: 11676\n",
      "Chunk 13 processed. Total matches found: 12649\n",
      "Chunk 14 processed. Total matches found: 13622\n",
      "Chunk 15 processed. Total matches found: 14595\n",
      "Chunk 16 processed. Total matches found: 15568\n",
      "Chunk 17 processed. Total matches found: 15573\n"
     ]
    }
   ],
   "source": [
    "# Matches looks like:\n",
    "# {plaintiff_name: (best_match_llc, confidence_score)}\n",
    "matches = parallel_match_plaintiffs(plaintiffs, llcs, chunk_size=chunk_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df['match_tuple'] = evictions_df['plaintiff_name_normalized'].map(matches) # Match tuple looks like (best_match, confidence_score)\n",
    "# Unpack into two separate columns\n",
    "evictions_df[['best_match', 'match_confidence']] = pd.DataFrame(evictions_df['match_tuple'].tolist(), index=evictions_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.merge(\n",
    "    left=evictions_df,\n",
    "    right=llc_df,\n",
    "    left_on='best_match',\n",
    "    right_on='EntityID_normalized',\n",
    "    how='left'\n",
    ").drop(columns=['best_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df.to_parquet('evictions_matched.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
