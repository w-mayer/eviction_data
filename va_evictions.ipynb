{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement fuzzy matching on LLCs that have filed evictions to lookup registered LLC info\n",
    "\n",
    "Updated 4/8/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from rapidfuzz import process, fuzz\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/gtcbtj4n6mjf4mwvq3711yw40000gn/T/ipykernel_2688/1095993889.py:1: DtypeWarning: Columns (0,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  a = pd.read_csv('DATA/llc.csv')\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv('DATA/llc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/gtcbtj4n6mjf4mwvq3711yw40000gn/T/ipykernel_2688/2962749221.py:15: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    EntityID      Name  \\\n",
      "\\t11072857                                TJ PROPERTIES, LLC  INACTIVE   \n",
      "\\t11159320    Rehab Developrs & Management House Buyers, LLC  INACTIVE   \n",
      "\\t11468309               SIMPLISTIC HOLISTIC PHOTOGRAPHY LLC  INACTIVE   \n",
      "\\t00601153                            Handy Distribution LLC    ACTIVE   \n",
      "\\t00036251                  Lumos Telephone of Botetourt LLC    ACTIVE   \n",
      "\n",
      "                Status StatusReason Status Date    Duration IncorpDate  \\\n",
      "\\t11072857    Rejected   2020-07-06  9999-12-31         NaN         VA   \n",
      "\\t11159320    Rejected   2021-01-13  9999-12-31         NaN         VA   \n",
      "\\t11468309    Rejected   2022-12-07  9999-12-31         NaN         VA   \n",
      "\\t00601153      Active   2006-03-17  9999-12-31  1899-02-16         VA   \n",
      "\\t00036251      Active   2019-04-26  9999-12-31  1901-02-23         VA   \n",
      "\n",
      "                 IncorpState IndustryCode Street1  ... RA-EffDate RA-Status  \\\n",
      "\\t11072857               NaN          NaN     NaN  ...     Active       NaN   \n",
      "\\t11159320               NaN          NaN     NaN  ...        NaN       NaN   \n",
      "\\t11468309               NaN          NaN     NaN  ...        NaN       NaN   \n",
      "\\t00601153       0 - General   65 10th St     NaN  ...     Active       680   \n",
      "\\t00036251    12 - Telephone  1 Lumos Plz     NaN  ...     Active       760   \n",
      "\n",
      "             RA-Loc StockInd TotalShares MergerInd AssessInd Is Series LLC  \\\n",
      "\\t11072857      NaN      0.0         NaN         1       NaN           NaN   \n",
      "\\t11159320      NaN      NaN         NaN         1       NaN           NaN   \n",
      "\\t11468309      NaN      NaN         NaN         1       NaN           NaN   \n",
      "\\t00601153      NaN      0.0           S         1       NaN           NaN   \n",
      "\\t00036251      NaN      0.0           S         1       NaN           NaN   \n",
      "\n",
      "             Is Protected Series Series LLC ID  \n",
      "\\t11072857                   NaN           NaN  \n",
      "\\t11159320                   NaN           NaN  \n",
      "\\t11468309                   NaN           NaN  \n",
      "\\t00601153                   NaN           NaN  \n",
      "\\t00036251                   NaN           NaN  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"DATA/llc.csv\", \n",
    "                 delimiter=\",\", \n",
    "                 skipinitialspace=True,  # Skip spaces after delimiter\n",
    "                 quotechar='\"',          # Properly handle quoted fields\n",
    "                 dtype=str)              # Load all columns as strings initially\n",
    "\n",
    "# Clean up column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# If the first column is empty or just contains indices\n",
    "if df.columns[0] == 'Unnamed: 0' or df.columns[0].strip() == '':\n",
    "    df = df.iloc[:, 1:]  # Remove the first column\n",
    "\n",
    "# Further cleanup if needed\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Display the cleaned dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EntityID', 'Name', 'Status', 'StatusReason', 'Status Date', 'Duration',\n",
       "       'IncorpDate', 'IncorpState', 'IndustryCode', 'Street1', 'Street2',\n",
       "       'City', 'State', 'Zip', 'PrinOffEffDate', 'RA-Name', 'RA-Street1',\n",
       "       'RA-Street2', 'RA-City', 'RA-State', 'RA-Zip', 'RA-EffDate',\n",
       "       'RA-Status', 'RA-Loc', 'StockInd', 'TotalShares', 'MergerInd',\n",
       "       'AssessInd', 'Is Series LLC', 'Is Protected Series', 'Series LLC ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.read_parquet('evictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llc_df = pd.read_parquet('llc.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservative pre-processing approach to maintain efficiency\n",
    "\n",
    "Can make this more aggressive if it doesn't work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_names(df, column_name):\n",
    "    \"\"\"\n",
    "    Normalize names, sort words alphabetically for natural language processing if we need it later\n",
    "    @df: pandas dataframe\n",
    "    @column_name: str column name to preprocess\n",
    "    \n",
    "    \"\"\"\n",
    "    column = column_name + \"_normalized\"\n",
    "    df[column] = (\n",
    "        df[column_name]\n",
    "        .str.lower()\n",
    "        .str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.strip()\n",
    "    ) \n",
    "\n",
    "    df[column] = (\n",
    "        df[column]\n",
    "        .str.split()\n",
    "        .map(lambda x: \" \".join(sorted(x)) if isinstance(x, list) else ' ')\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e_columns_for_p = ['plaintiff_name'] # columns for preprocessing, add more as needed\n",
    "l_columns_for_p = ['EntityID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in e_columns_for_p: # apply preprocessing for both df\n",
    "    evictions_df = preprocess_names(evictions_df, i)\n",
    "\n",
    "for i in l_columns_for_p:\n",
    "    llc_df = preprocess_names(llc_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_229293/4089579124.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  evictions_df[\"is_llc\"] = evictions_df[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)\n"
     ]
    }
   ],
   "source": [
    "# create flag 'is_llc' to restrict lookup to only llcs\n",
    "llc_keywords = r\"\\b(llc|l\\.l\\.c|inc|inc\\.|corporation|corp|corp\\.|co|co\\.|company|ltd|ltd\\.|lp|l\\.p\\.|pllc|plc|plc\\.|limited|limited liability company)\\b\"\n",
    "evictions_df[\"is_llc\"] = evictions_df[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we've set the 'is_llc' flag, we can remove these terms to reduce noise\n",
    "suffixes = [\n",
    "    \"llc\", \"l.l.c\", \"inc\", \"incorporated\", \"corp\", \"corporation\",\n",
    "    \"co\", \"company\", \"ltd\", \"l.p\", \"lp\", \"pllc\", \"plc\", \"llp\", \"p.c\"\n",
    "]\n",
    "\n",
    "suffix_pattern = r'\\s*(?:' + '|'.join(suffixes) + r')\\.?\\s*$'\n",
    "\n",
    "evictions_df['plaintiff_name_normalized'] = evictions_df['plaintiff_name_normalized'].str.replace(suffix_pattern, '', regex=True)\n",
    "llc_df['EntityID_normalized'] = llc_df['EntityID_normalized'].str.replace(suffix_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = evictions_df[evictions_df['is_llc']] # restrict lookup to only llcs\n",
    "plaintiffs = set(evictions_df['plaintiff_name_normalized']) # set of unique LLC plaintiffs\n",
    "llcs = list(set(llc_df['EntityID_normalized'])) # set of unique registered LLCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process matching for a subset of plaintiff names\n",
    "def process_chunk(plaintiff_chunk, llc_names, confidence=80):\n",
    "    matches = {}\n",
    "    for i, plaintiff in enumerate(plaintiff_chunk):\n",
    "        best_match, score, _ = process.extractOne(plaintiff, llc_names, scorer=fuzz.WRatio)\n",
    "        # if best_match and score >= confidence:\n",
    "        matches[plaintiff] = (best_match, score)\n",
    "        # else:\n",
    "            # matches[plaintiff] = (None, 0)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} out of {len(plaintiff_chunk)} plaintiffs in this chunk.\")\n",
    "    return matches\n",
    "\n",
    "# Function to split the plaintiff set and process in parallel\n",
    "def parallel_match_plaintiffs(plaintiff_names_set, llc_names_set, chunk_size=1000):\n",
    "    plaintiff_chunks = [list(plaintiff_names_set)[i:i + chunk_size] for i in range(0, len(plaintiff_names_set), chunk_size)]\n",
    "    print(f\"Total of {len(plaintiff_chunks)} chunks to process.\")\n",
    "\n",
    "    all_matches = {}\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_chunk, chunk, llc_names_set) for chunk in plaintiff_chunks]\n",
    "        for i, future in enumerate(futures):\n",
    "            all_matches.update(future.result())\n",
    "            print(f\"Chunk {i + 1} processed. Total matches found: {len(all_matches)}\")\n",
    "    \n",
    "    return all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = len(plaintiffs) // 16 # adjust for num of cores, 16 worked well under an hour\n",
    "# probably only needed ~100GB memory or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 17 chunks to process.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 100 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 200 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 300 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 400 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 500 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 600 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 700 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 800 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Processed 900 out of 972 plaintiffs in this chunk.\n",
      "Chunk 1 processed. Total matches found: 972\n",
      "Chunk 2 processed. Total matches found: 1944\n",
      "Chunk 3 processed. Total matches found: 2916\n",
      "Chunk 4 processed. Total matches found: 3888\n",
      "Chunk 5 processed. Total matches found: 4860\n",
      "Chunk 6 processed. Total matches found: 5832\n",
      "Chunk 7 processed. Total matches found: 6804\n",
      "Chunk 8 processed. Total matches found: 7776\n",
      "Chunk 9 processed. Total matches found: 8748\n",
      "Chunk 10 processed. Total matches found: 9720\n",
      "Chunk 11 processed. Total matches found: 10692\n",
      "Chunk 12 processed. Total matches found: 11664\n",
      "Chunk 13 processed. Total matches found: 12636\n",
      "Chunk 14 processed. Total matches found: 13608\n",
      "Chunk 15 processed. Total matches found: 14580\n",
      "Chunk 16 processed. Total matches found: 15552\n",
      "Chunk 17 processed. Total matches found: 15564\n"
     ]
    }
   ],
   "source": [
    "# Matches looks like:\n",
    "# {plaintiff_name: (best_match_llc, confidence_score)}\n",
    "matches = parallel_match_plaintiffs(plaintiffs, llcs, chunk_size=chunk_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df['match_tuple'] = evictions_df['plaintiff_name_normalized'].map(matches) # Match tuple looks like (best_match, confidence_score)\n",
    "# Unpack into two separate columns\n",
    "evictions_df[['best_match', 'match_confidence']] = pd.DataFrame(evictions_df['match_tuple'].tolist(), index=evictions_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.merge(\n",
    "    left=evictions_df,\n",
    "    right=llc_df,\n",
    "    left_on='best_match',\n",
    "    right_on='EntityID_normalized',\n",
    "    how='left'\n",
    ").drop(columns=['best_match', 'match_tuple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df.to_parquet('evictions_matched.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
