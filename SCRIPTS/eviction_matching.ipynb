{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement fuzzy matching on LLCs that have filed evictions to lookup registered LLC info\n",
    "\n",
    "Updated 5/6/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn box API, show something about how to pull evictions_df from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.read_parquet('evictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llc_df = pd.read_parquet('LLC_clean.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservative pre-processing approach to maintain efficiency\n",
    "\n",
    "Can make this more aggressive if it doesn't work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_names(df, column_name):\n",
    "    \"\"\"\n",
    "    Normalize names\n",
    "    @df: pandas dataframe\n",
    "    @column_name: str column name to preprocess\n",
    "    \n",
    "    \"\"\"\n",
    "    column = column_name + \"_normalized\"\n",
    "    df[column] = (\n",
    "        df[column_name]\n",
    "        .str.lower()\n",
    "        .str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.strip()\n",
    "    ) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e_columns_for_p = ['plaintiff_name', 'plaintiff_attorney'] # columns for preprocessing, add more as needed\n",
    "l_columns_for_p = ['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in e_columns_for_p: # apply preprocessing for both df\n",
    "    evictions_df = preprocess_names(evictions_df, column)\n",
    "\n",
    "for column in l_columns_for_p:\n",
    "    llc_df = preprocess_names(llc_df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_157268/4089579124.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  evictions_df[\"is_llc\"] = evictions_df[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)\n"
     ]
    }
   ],
   "source": [
    "# create flag 'is_llc' to restrict lookup to only llcs\n",
    "llc_keywords = r\"\\b(llc|l\\.l\\.c|inc|inc\\.|corporation|corp|corp\\.|co|co\\.|company|ltd|ltd\\.|lp|l\\.p\\.|pllc|plc|plc\\.|limited|limited liability company)\\b\"\n",
    "evictions_df[\"is_llc\"] = evictions_df[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we've set the 'is_llc' flag, we can remove these terms to reduce noise\n",
    "suffixes = [\n",
    "    \"llc\", \"l.l.c\", \"inc\", \"incorporated\", \"corp\", \"corporation\",\n",
    "    \"co\", \"company\", \"ltd\", \"l.p\", \"lp\", \"pllc\", \"plc\", \"llp\", \"p.c\"\n",
    "]\n",
    "\n",
    "suffix_pattern = r'\\s*(?:' + '|'.join(suffixes) + r')\\.?\\s*$'\n",
    "\n",
    "evictions_df['plaintiff_name_normalized'] = evictions_df['plaintiff_name_normalized'].str.replace(suffix_pattern, '', regex=True)\n",
    "llc_df['Name_normalized'] = llc_df['Name_normalized'].str.replace(suffix_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = evictions_df[evictions_df['is_llc']] # restrict lookup to only llcs\n",
    "plaintiffs = evictions_df['plaintiff_name_normalized'].dropna().unique().tolist()\n",
    "llcs = llc_df['Name_normalized'].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process matching for a subset of plaintiff names\n",
    "def process_chunk(plaintiff_chunk, llc_names, confidence=80):\n",
    "    matches = {}\n",
    "    for i, plaintiff in enumerate(plaintiff_chunk):\n",
    "        try:\n",
    "            best_match, score, _ = process.extractOne(plaintiff, llc_names, scorer=fuzz.WRatio)\n",
    "            matches[plaintiff] = (best_match, score) if score >= confidence else (None, 0)\n",
    "        except Exception as e:\n",
    "            matches[plaintiff] = (None, 0)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} out of {len(plaintiff_chunk)} plaintiffs in this chunk.\")\n",
    "    return matches\n",
    "\n",
    "# Function to split the plaintiff set and process in parallel\n",
    "def parallel_match_plaintiffs(plaintiff_names_set, llc_names_set, chunk_size=1000):\n",
    "    plaintiff_chunks = [list(plaintiff_names_set)[i:i + chunk_size] for i in range(0, len(plaintiff_names_set), chunk_size)]\n",
    "    print(f\"Total of {len(plaintiff_chunks)} chunks to process.\")\n",
    "\n",
    "    all_matches = {}\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_chunk, chunk, llc_names_set) for chunk in plaintiff_chunks]\n",
    "        for i, future in enumerate(futures):\n",
    "            all_matches.update(future.result())\n",
    "            print(f\"Chunk {i + 1} processed. Total matches found: {len(all_matches)}\")\n",
    "    \n",
    "    return all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = len(plaintiffs) // 16 # adjust for num of cores, 16 worked well under an hour\n",
    "# probably only needed ~50gb memory or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 17 chunks to process.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 100 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 200 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 300 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 400 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 500 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 600 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 700 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 800 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Chunk 1 processed. Total matches found: 1003\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 900 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Chunk 2 processed. Total matches found: 2006\n",
      "Chunk 3 processed. Total matches found: 3009\n",
      "Chunk 4 processed. Total matches found: 4012\n",
      "Chunk 5 processed. Total matches found: 5015\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Chunk 6 processed. Total matches found: 6018\n",
      "Chunk 7 processed. Total matches found: 7021\n",
      "Chunk 8 processed. Total matches found: 8024\n",
      "Chunk 9 processed. Total matches found: 9027\n",
      "Chunk 10 processed. Total matches found: 10030\n",
      "Chunk 11 processed. Total matches found: 11033\n",
      "Chunk 12 processed. Total matches found: 12036\n",
      "Chunk 13 processed. Total matches found: 13039\n",
      "Chunk 14 processed. Total matches found: 14042\n",
      "Chunk 15 processed. Total matches found: 15045\n",
      "Processed 1000 out of 1003 plaintiffs in this chunk.\n",
      "Chunk 16 processed. Total matches found: 16048\n",
      "Chunk 17 processed. Total matches found: 16055\n"
     ]
    }
   ],
   "source": [
    "# Matches looks like:\n",
    "# {plaintiff_name: (best_match_llc, confidence_score)}\n",
    "matches = parallel_match_plaintiffs(plaintiffs, llcs, chunk_size=chunk_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df['match_tuple'] = evictions_df['plaintiff_name_normalized'].map(matches) # Match tuple looks like (best_match, confidence_score)\n",
    "# Unpack into two separate columns\n",
    "evictions_df[['best_match', 'match_confidence']] = pd.DataFrame(evictions_df['match_tuple'].tolist(), index=evictions_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.merge(\n",
    "    left=evictions_df,\n",
    "    right=llc_df,\n",
    "    left_on='best_match',\n",
    "    right_on='Name_normalized',\n",
    "    how='left'\n",
    ").drop(columns=['best_match', 'match_tuple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df.to_parquet('evictions_matched.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches = evictions_df.copy()\n",
    "matches = matches.sort_values(by='match_confidence', ascending=False)\n",
    "matches = matches[['plaintiff_name', 'Name', 'match_confidence']]\n",
    "matches = matches.drop_duplicates()\n",
    "matches.to_csv('full_matches.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
