{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement fuzzy matching on LLCs that have filed evictions to lookup registered LLC info\n",
    "\n",
    "Updated 5/6/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn box API, show something about how to pull evictions_df from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.read_parquet('../DATA/evictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llc_df = pd.read_parquet('../DATA/LLC_clean.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conservative pre-processing approach to maintain efficiency\n",
    "\n",
    "Can make this more aggressive if it doesn't work out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_names(df, column_name):\n",
    "    \"\"\"\n",
    "    Normalize names, sort words alphabetically for natural language processing if we need it later\n",
    "    @df: pandas dataframe\n",
    "    @column_name: str column name to preprocess\n",
    "    \n",
    "    \"\"\"\n",
    "    column = column_name + \"_normalized\"\n",
    "    df[column] = (\n",
    "        df[column_name]\n",
    "        .str.lower()\n",
    "        .str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.strip()\n",
    "    ) \n",
    "\n",
    "    df[column] = (\n",
    "        df[column]\n",
    "        .str.split()\n",
    "        .map(lambda x: \" \".join(sorted(x)) if isinstance(x, list) else ' ')\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e_columns_for_p = ['plaintiff_name', 'plaintiff_attorney'] # columns for preprocessing, add more as needed\n",
    "l_columns_for_p = ['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in e_columns_for_p: # apply preprocessing for both df\n",
    "    evictions_df = preprocess_names(evictions_df, column)\n",
    "\n",
    "for column in l_columns_for_p:\n",
    "    llc_df = preprocess_names(llc_df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/gtcbtj4n6mjf4mwvq3711yw40000gn/T/ipykernel_3285/4089579124.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  evictions_df[\"is_llc\"] = evictions_df[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)\n"
     ]
    }
   ],
   "source": [
    "# create flag 'is_llc' to restrict lookup to only llcs\n",
    "llc_keywords = r\"\\b(llc|l\\.l\\.c|inc|inc\\.|corporation|corp|corp\\.|co|co\\.|company|ltd|ltd\\.|lp|l\\.p\\.|pllc|plc|plc\\.|limited|limited liability company)\\b\"\n",
    "evictions_df[\"is_llc\"] = evictions_df[\"plaintiff_name_normalized\"].str.contains(llc_keywords, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we've set the 'is_llc' flag, we can remove these terms to reduce noise\n",
    "suffixes = [\n",
    "    \"llc\", \"l.l.c\", \"inc\", \"incorporated\", \"corp\", \"corporation\",\n",
    "    \"co\", \"company\", \"ltd\", \"l.p\", \"lp\", \"pllc\", \"plc\", \"llp\", \"p.c\"\n",
    "]\n",
    "\n",
    "suffix_pattern = r'\\s*(?:' + '|'.join(suffixes) + r')\\.?\\s*$'\n",
    "\n",
    "evictions_df['plaintiff_name_normalized'] = evictions_df['plaintiff_name_normalized'].str.replace(suffix_pattern, '', regex=True)\n",
    "llc_df['Name_normalized'] = llc_df['Name_normalized'].str.replace(suffix_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = evictions_df[evictions_df['is_llc']] # restrict lookup to only llcs\n",
    "plaintiffs = list(set(evictions_df['plaintiff_name_normalized'])) # set of unique LLC plaintiffs\n",
    "llcs = list(set(llc_df['Name_normalized'])) # set of unique registered LLCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process matching for a subset of plaintiff names\n",
    "def process_chunk(plaintiff_chunk, llc_names, confidence=80):\n",
    "    matches = {}\n",
    "    for i, plaintiff in enumerate(plaintiff_chunk):\n",
    "        best_match, score, _ = process.extractOne(plaintiff, llc_names, scorer=fuzz.WRatio)\n",
    "        if best_match and score >= confidence:\n",
    "            matches[plaintiff] = (best_match, score)\n",
    "        else:\n",
    "            matches[plaintiff] = (None, 0)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} out of {len(plaintiff_chunk)} plaintiffs in this chunk.\")\n",
    "    return matches\n",
    "\n",
    "# Function to split the plaintiff set and process in parallel\n",
    "def parallel_match_plaintiffs(plaintiff_names_set, llc_names_set, chunk_size=1000):\n",
    "    plaintiff_chunks = [list(plaintiff_names_set)[i:i + chunk_size] for i in range(0, len(plaintiff_names_set), chunk_size)]\n",
    "    print(f\"Total of {len(plaintiff_chunks)} chunks to process.\")\n",
    "\n",
    "    all_matches = {}\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_chunk, chunk, llc_names_set) for chunk in plaintiff_chunks]\n",
    "        for i, future in enumerate(futures):\n",
    "            all_matches.update(future.result())\n",
    "            print(f\"Chunk {i + 1} processed. Total matches found: {len(all_matches)}\")\n",
    "    \n",
    "    return all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = len(plaintiffs) // 16 # adjust for num of cores, 16 worked well under an hour\n",
    "# probably only needed ~50gb memory or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Matches looks like:\n",
    "# {plaintiff_name: (best_match_llc, confidence_score)}\n",
    "matches = parallel_match_plaintiffs(plaintiffs, llcs, chunk_size=chunk_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df['match_tuple'] = evictions_df['plaintiff_name_normalized'].map(matches) # Match tuple looks like (best_match, confidence_score)\n",
    "# Unpack into two separate columns\n",
    "evictions_df[['best_match', 'match_confidence']] = pd.DataFrame(evictions_df['match_tuple'].tolist(), index=evictions_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df = pd.merge(\n",
    "    left=evictions_df,\n",
    "    right=llc_df,\n",
    "    left_on='best_match',\n",
    "    right_on='Name_normalized',\n",
    "    how='left'\n",
    ").drop(columns=['best_match', 'match_tuple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evictions_df.to_parquet('evictions_matched.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = evictions_df.copy()\n",
    "matches = matches.sort_values(by='match_confidence', ascending=False)\n",
    "matches = matches[['plaintiff_name', 'Name', 'match_confidence']]\n",
    "matches = matches.drop_duplicates()\n",
    "matches.to_csv('../OUTPUT/full_matches.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
